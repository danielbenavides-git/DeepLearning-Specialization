{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef8aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf2ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: zero_pad\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 1 line)\n",
    "    # X_pad = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589c072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 9, 9, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af2cfafdd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 3)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1, 1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1, 1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0, :, :, 0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d56745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_single_step\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    #(≈ 3 lines of code)\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    # s = None\n",
    "    # Sum over all entries of the volume s.\n",
    "    # Z = None\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    # Z = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    s = np.multiply(a_slice_prev, W)\n",
    "    Z = np.sum(s)\n",
    "    Z = Z + float(b)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ec3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_forward\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    # (m, n_H_prev, n_W_prev, n_C_prev) = None\n",
    "    \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    # (f, f, n_C_prev, n_C) = None\n",
    "    \n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    # stride = None\n",
    "    # pad = None\n",
    "    \n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    # n_H = None\n",
    "    # n_W = None\n",
    "\n",
    "    n_H = int((n_H_prev + 2 * pad - f) / stride) + 1\n",
    "    n_W = int((n_W_prev + 2 * pad - f) / stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    # Z = None\n",
    "\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    # A_prev_pad = None\n",
    "    \n",
    "    # for i in range(None):               # loop over the batch of training examples\n",
    "        # a_prev_pad = None               # Select ith training example's padded activation\n",
    "        # for h in range(None):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            # vert_start = None\n",
    "            # vert_end = None\n",
    "            \n",
    "            # for w in range(None):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                # horiz_start = None\n",
    "                # horiz_end = None\n",
    "                \n",
    "                # for c in range(None):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    # a_slice_prev = None\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    # weights = None\n",
    "                    # biases = None\n",
    "                    # Z[i, h, w, c] = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    for i in range(m):               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev[i, :, :, :]\n",
    "        a_prev_pad = np.pad(a_prev_pad, ((pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):\n",
    "                    \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427d355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    # for i in range(None):                         # loop over the training examples\n",
    "        # for h in range(None):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            # vert_start = None\n",
    "            # vert_end = None\n",
    "            \n",
    "            # for w in range(None):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                # horiz_start = None\n",
    "                # horiz_end = None\n",
    "                \n",
    "                # for c in range (None):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    # a_prev_slice = None\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    # if mode == \"max\":\n",
    "                        # A[i, h, w, c] = None\n",
    "                    # elif mode == \"average\":\n",
    "                        # A[i, h, w, c] = None\n",
    "    \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            \n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                \n",
    "                for c in range(n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    # Compute the pooling operation on the slice. \n",
    "                    # Use an if statement to differentiate the modes. \n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    #assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3575af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
    "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
    "          numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
    "          numpy array of shape (1, 1, 1, n_C)\n",
    "    \"\"\"    \n",
    "    \n",
    "        \n",
    "    # Retrieve information from \"cache\"\n",
    "    # (A_prev, W, b, hparameters) = None\n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    # (m, n_H_prev, n_W_prev, n_C_prev) = None\n",
    "    # Retrieve dimensions from W's shape\n",
    "    # (f, f, n_C_prev, n_C) = None\n",
    "\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    # stride = None\n",
    "    # pad = None\n",
    "\n",
    "    stride = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    # (m, n_H, n_W, n_C) = None\n",
    "    \n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "\n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    # dA_prev = None                          \n",
    "    # dW = None\n",
    "    # db = None\n",
    "\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "    \n",
    "    # Pad A_prev and dA_prev\n",
    "    # A_prev_pad = zero_pad(A_prev, pad)\n",
    "    # dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "    \n",
    "    #for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        # a_prev_pad = None\n",
    "        # da_prev_pad = None\n",
    "        \n",
    "        #for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "        #    for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "        #        for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    # vert_start = None\n",
    "                    # vert_end = None\n",
    "                    # horiz_start = None\n",
    "                    # horiz_end = None\n",
    "\n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    # a_slice = None\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    # da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += None\n",
    "                    # dW[:,:,:,c] += None\n",
    "                    # db[:,:,:,c] += None\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        # dA_prev[i, :, :, :] = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    \n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:, :, :, c] * dZ[i, h, w, c]\n",
    "                    dW[:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:, :, :, c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61451f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    \"\"\"\n",
    "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- Array of shape (f, f)\n",
    "    \n",
    "    Returns:\n",
    "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
    "    \"\"\"    \n",
    "    # (≈1 line)\n",
    "    # mask = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    mask = (x == np.max(x))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9277d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"    \n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    # (n_H, n_W) = None\n",
    "\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    # average = None\n",
    "\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    # a = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    a = np.ones(shape) * average\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d07990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
    "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
    "    \"\"\"\n",
    "    # Retrieve information from cache (≈1 line)\n",
    "    # (A_prev, hparameters) = None\n",
    "    \n",
    "    (A_prev, hparameters) = cache\n",
    "\n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
    "    # stride = None\n",
    "    # f = None\n",
    "\n",
    "    stride = hparameters[\"stride\"]\n",
    "    f = hparameters[\"f\"]\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    # m, n_H_prev, n_W_prev, n_C_prev = None\n",
    "    # m, n_H, n_W, n_C = None\n",
    "\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    (m, n_H, n_W, n_C) = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    # dA_prev = None\n",
    "\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    # for i in range(None): # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev (≈1 line)\n",
    "        # a_prev = None\n",
    "        \n",
    "        # for h in range(n_H):                   # loop on the vertical axis\n",
    "            # for w in range(n_W):               # loop on the horizontal axis\n",
    "                # for c in range(n_C):           # loop over the channels (depth)\n",
    "        \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    # vert_start = None\n",
    "                    # vert_end = None\n",
    "                    # horiz_start = None\n",
    "                    # horiz_end = None\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    # if mode == \"max\":\n",
    "                        \n",
    "                        # Use the corners and \"c\" to define the current slice from a_prev (≈1 line)\n",
    "                        # a_prev_slice = None\n",
    "                        \n",
    "                        # Create the mask from a_prev_slice (≈1 line)\n",
    "                        # mask = None\n",
    "\n",
    "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)\n",
    "                        # dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
    "                        \n",
    "                    # elif mode == \"average\":\n",
    "                        \n",
    "                        # Get the value da from dA (≈1 line)\n",
    "                        # da = None\n",
    "                        \n",
    "                        # Define the shape of the filter as fxf (≈1 line)\n",
    "                        # shape = None\n",
    "\n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
    "                        # dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i, :, :, :]\n",
    "        \n",
    "        for h in range(n_H):                   # loop on the vertical axis\n",
    "            for w in range(n_W):               # loop on the horizontal axis\n",
    "                for c in range(n_C):           # loop over the channels (depth)\n",
    "                    \n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += mask * dA[i, h, w, c]\n",
    "                        \n",
    "                    elif mode == \"average\":\n",
    "                        da = dA[i, h, w, c]\n",
    "                        shape = (f, f)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)\n",
    "\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
